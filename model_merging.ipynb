{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPEwHHnHxu5x20O58Sr2IB5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Loki-33/Mergex/blob/main/model_merging.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoModelForSequenceClassification"
      ],
      "metadata": {
        "id": "vCbxaE_Lz61e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SLERP METHOD"
      ],
      "metadata": {
        "id": "rET4OiFl0Ac2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
        "tokenizer1 = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0Y8N2nk0AXM",
        "outputId": "aaa2dca9-58e8-4a70-e9c0-6e3daccb0477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
        "tokenizer2 = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOIwBv3C0ASI",
        "outputId": "a68bb0f5-ad97-45d9-c7af-22625605b7e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parameters1= sum([p.numel() for p in model1.parameters()])"
      ],
      "metadata": {
        "id": "F5WVwh5pz6vY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters2 = sum([p.numel() for p in model2.parameters()])"
      ],
      "metadata": {
        "id": "4CI1fPIJz6nr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#LERP METHOD"
      ],
      "metadata": {
        "id": "D4CN2U3T3LYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_state_dict = {}"
      ],
      "metadata": {
        "id": "w52DIR6_7BFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "alpha=0.5"
      ],
      "metadata": {
        "id": "FMtZbvH97L6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for key in model2.distilbert.embeddings.state_dict():\n",
        "  A=model1.bert.embeddings.state_dict()[key]\n",
        "  B = model2.distilbert.embeddings.state_dict()[key]\n",
        "  merged_state_dict[f\"distilbert.embeddings.{key}\"] = alpha * A + (1 - alpha) * B"
      ],
      "metadata": {
        "id": "7pW30XS53LU4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1_layers = list(model1.bert.encoder.layer)\n",
        "model2_layers = list(model2.distilbert.transformer.layer)"
      ],
      "metadata": {
        "id": "V_xgGuMCz6bA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,j in zip(model1_layers, model2_layers):\n",
        "  if i == j:\n",
        "    print(i, j)"
      ],
      "metadata": {
        "id": "zp7OwQrm975G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for i, distil_layer in enumerate(model2_layers):\n",
        "#   bert_idx1, bert_idx2 = 2*i, 2*i+1\n",
        "#   bert_layer_avg = {\n",
        "#       k: 0.5 * v1 + 0.5 * v2 for (k, v1), (_, v2) in \\\n",
        "#       zip(model1_layers[bert_idx1].state_dict().items(), \\\n",
        "#           model2_layers[i].state_dict().items())\n",
        "#   }\n",
        "#   for k,v in distil_layer.state_dict().items():\n",
        "#     A = bert_layer_avg[k]\n",
        "#     B = v\n",
        "#     merged_state_dict[f\"distilbert.transformer.layer.{i}.{k}\"] = alpha * A + (1 - alpha) * B\n"
      ],
      "metadata": {
        "id": "j8PMDD_bz6UL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.bert.pooler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2R6-Npb8z6NI",
        "outputId": "5d057bb4-44cd-4a3b-c04e-855f802250ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertPooler(\n",
              "  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (activation): Tanh()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lerp(x1, x2, alpha=0.5):\n",
        "  return (1-alpha)*x1 + alpha*x2"
      ],
      "metadata": {
        "id": "QsLS7Sydz6Bn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge(bert_model, distil_model, alpha=0.5):\n",
        "  new_state = distil_model.state_dict().copy()\n",
        "  #EMBEDDINGS\n",
        "  for key in ['embeddings.word_embeddings.weight', \"embeddings.position_embeddings.weight\"]:\n",
        "    new_state[key] = lerp(\n",
        "        bert_model.state_dict()[f\"bert.{key}\"],\n",
        "        distil_model.state_dict()[f\"distilbert.{key}\"],\n",
        "        alpha=alpha\n",
        "    )\n",
        "\n",
        "  #trransformer leayer\n",
        "  bert_layers = bert_model.bert.encoder.layer\n",
        "  distil_layers = distil_model.distilbert.transformer.layer\n",
        "\n",
        "  for distil_idx in range(6):\n",
        "    bert_idx1, bert_idx2 = 2*distil_idx, 2*distil_idx+1\n",
        "    bert_layer1 = bert_layers[bert_idx1].state_dict()\n",
        "    bert_layer2 = bert_layers[bert_idx2].state_dict()\n",
        "    distil_layer = distil_layers[distil_idx].state_dict()\n",
        "\n",
        "    merged={}\n",
        "    for k in distil_layer.keys():\n",
        "      if 'q_lin' in k:\n",
        "        k1, k2 = \"attention.self.query.\" + k.split(\".\")[-1], \"attention.self.query.\" + k.split(\".\")[-1]\n",
        "      elif \"k_lin\" in k:\n",
        "        k1, k2 = \"attention.self.key.\" + k.split(\".\")[-1], \"attention.self.key.\" + k.split(\".\")[-1]\n",
        "      elif 'v_lin' in k:\n",
        "        k1, k2 = \"attention.self.value.\" + k.split(\".\")[-1], \"attention.self.value.\" + k.split(\".\")[-1]\n",
        "      elif 'out_lin' in k:\n",
        "        k1, k2 = \"attention.output.dense.\" + k.split(\".\")[-1], \"attention.output.dense.\" + k.split(\".\")[-1]\n",
        "      elif \"ffn.lin1\" in k:\n",
        "        k1, k2 = \"intermediate.dense.\" + k.split(\".\")[-1], \"intermediate.dense.\" + k.split(\".\")[-1]\n",
        "      elif 'ffn.lin2' in k:\n",
        "        k1, k2 = \"output.dense.\" + k.split(\".\")[-1], \"output.dense.\" + k.split(\".\")[-1]\n",
        "      elif \"sa_layer_norm\" in k:\n",
        "        k1, k2 = \"attention.output.LayerNorm.\" + k.split(\".\")[-1], \"attention.output.LayerNorm.\" + k.split(\".\")[-1]\n",
        "      elif \"output_layer_norm\" in k:\n",
        "        k1, k2 = \"output.LayerNorm.\" + k.split(\".\")[-1], \"output.LayerNorm.\" + k.split(\".\")[-1]\n",
        "      else:\n",
        "        continue\n",
        "\n",
        "      bert_avg = 0.5 * bert_layer1[k1] + 0.5 * bert_layer2[k2]\n",
        "      merged[k] = lerp(bert_avg, distil_layer[k], alpha=alpha)\n",
        "\n",
        "    for k,v in merged.items():\n",
        "      new_state[f\"distilbert.transformer.layer.{distil_idx}.{k}\"] = v\n",
        "  if 'pre_classifier.weight' in new_state:\n",
        "    new_state['pre_classifier.weight'] = distil_model.state_dict()[\"pre_classifier.weight\"]\n",
        "    new_state[\"pre_classifier.bias\"]   = distil_model.state_dict()[\"pre_classifier.bias\"]\n",
        "\n",
        "  distil_model.load_state_dict(new_state, strict=False)\n",
        "  return distil_model"
      ],
      "metadata": {
        "id": "MawtRv7_z59G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBSGIn0dz1dG"
      },
      "outputs": [],
      "source": [
        "merged_model = merge(model1, model2, alpha=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SSzK8U4DoZx",
        "outputId": "3dba01d7-81c3-492b-924f-0c8ff3c77fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DistilBertForSequenceClassification(\n",
              "  (distilbert): DistilBertModel(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (transformer): Transformer(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x TransformerBlock(\n",
              "          (attention): DistilBertSdpaAttention(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (ffn): FFN(\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (activation): GELUActivation()\n",
              "          )\n",
              "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              "  (dropout): Dropout(p=0.2, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer1.pad_token = tokenizer1.eos_token"
      ],
      "metadata": {
        "id": "RuqLOMbrEZ--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_texts = [\n",
        "    \"I love this movie, it was fantastic!\",   # positive\n",
        "    \"This product is terrible and I hate it\", # negative\n",
        "    \"The book was okay, nothing special\",     # neutral\n",
        "    \"Absolutely wonderful experience\",        # positive\n",
        "    \"Worst service Iâ€™ve ever had\",            # negative\n",
        "]\n",
        "\n",
        "sample_labels = torch.tensor([1, 0, 2, 1, 0],dtype=torch.float32)"
      ],
      "metadata": {
        "id": "0oYDDzRcERnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer1.pad_token = tokenizer1.eos_token"
      ],
      "metadata": {
        "id": "pdK7GXa7F-Xt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if tokenizer2.pad_token is None:\n",
        "    tokenizer2.add_special_tokens({'pad_token': '[PAD]'})\n",
        "tokenizer2.pad_token = '[PAD]'\n",
        "input_ids = tokenizer2(sample_texts, padding=True, truncation=True, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "7fY9KYU0F56i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  outputs = merged_model(**input_ids)\n",
        "  preds = torch.argmax(outputs.logits, dim=-1)\n",
        "\n",
        "correct = (preds == sample_labels).sum().item()\n",
        "accuracy = correct / len(sample_labels)\n",
        "\n",
        "print(f\"SImple Accuracy TEST: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ussAOYcBGSdR",
        "outputId": "43cb8eb9-51ad-494b-c849-092685c8f148"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SImple Accuracy TEST: 40.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "v3Qb8ydmG5h3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SLERP"
      ],
      "metadata": {
        "id": "wmlUbGQxG5dg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def slerp(A,B, alpha=0.5):\n",
        "    A_flat = A.view(-1)\n",
        "    B_flat = B.view(-1)\n",
        "    dot = torch.dot(A_flat, B_flat) / (A_flat.norm() * B_flat.norm())\n",
        "    dot = torch.clamp(dot, -1.0, 1.0)\n",
        "    theta = torch.acos(dot) * alpha\n",
        "    rel = (B_flat - A_flat * dot).div((B_flat - A_flat * dot).norm() + 1e-8)\n",
        "    res = (A_flat * torch.cos(theta) + rel * A_flat.norm() * torch.sin(theta))\n",
        "    return res.view_as(A)   # ðŸ”‘ reshape back"
      ],
      "metadata": {
        "id": "Q312qK7oFpRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge(bert_model, distil_model, alpha=0.5):\n",
        "  new_state = distil_model.state_dict().copy()\n",
        "  #EMBEDDINGS\n",
        "  for key in ['embeddings.word_embeddings.weight', \"embeddings.position_embeddings.weight\"]:\n",
        "    new_state[key] = slerp(\n",
        "        bert_model.state_dict()[f\"bert.{key}\"],\n",
        "        distil_model.state_dict()[f\"distilbert.{key}\"],\n",
        "        alpha=alpha\n",
        "    )\n",
        "\n",
        "  #trransformer leayer\n",
        "  bert_layers = bert_model.bert.encoder.layer\n",
        "  distil_layers = distil_model.distilbert.transformer.layer\n",
        "\n",
        "  for distil_idx in range(6):\n",
        "    bert_idx1, bert_idx2 = 2*distil_idx, 2*distil_idx+1\n",
        "    bert_layer1 = bert_layers[bert_idx1].state_dict()\n",
        "    bert_layer2 = bert_layers[bert_idx2].state_dict()\n",
        "    distil_layer = distil_layers[distil_idx].state_dict()\n",
        "\n",
        "    merged={}\n",
        "    for k in distil_layer.keys():\n",
        "      if 'q_lin' in k:\n",
        "        k_bert = \"attention.self.query.\" + k.split(\".\")[-1]\n",
        "\n",
        "      elif \"k_lin\" in k:\n",
        "        k_bert = \"attention.self.key.\" + k.split(\".\")[-1]\n",
        "      elif 'v_lin' in k:\n",
        "        k_bert = \"attention.self.value.\" + k.split(\".\")[-1]\n",
        "      elif 'out_lin' in k:\n",
        "        k_bert = \"attention.output.dense.\" + k.split(\".\")[-1]\n",
        "      elif \"ffn.lin1\" in k:\n",
        "        k_bert = \"intermediate.dense.\" + k.split(\".\")[-1]\n",
        "\n",
        "      elif 'ffn.lin2' in k:\n",
        "        k_bert = \"output.dense.\" + k.split(\".\")[-1]\n",
        "\n",
        "      elif \"sa_layer_norm\" in k:\n",
        "        k_bert = \"attention.output.LayerNorm.\" + k.split(\".\")[-1]\n",
        "      elif \"output_layer_norm\" in k:\n",
        "        k_bert = \"output.LayerNorm.\" + k.split(\".\")[-1]\n",
        "      else:\n",
        "        continue\n",
        "\n",
        "      bert_avg = 0.5 * bert_layer1[k_bert] + 0.5 * bert_layer2[k_bert]\n",
        "      merged[k] = slerp(bert_avg, distil_layer[k], alpha=alpha)\n",
        "\n",
        "    for k,v in merged.items():\n",
        "      new_state[f\"distilbert.transformer.layer.{distil_idx}.{k}\"] = v\n",
        "  if 'pre_classifier.weight' in new_state:\n",
        "    new_state['pre_classifier.weight'] = distil_model.state_dict()[\"pre_classifier.weight\"]\n",
        "    new_state[\"pre_classifier.bias\"]   = distil_model.state_dict()[\"pre_classifier.bias\"]\n",
        "\n",
        "  distil_model.load_state_dict(new_state, strict=False) #strict prevents crashing when some leys dont match\n",
        "  return distil_model"
      ],
      "metadata": {
        "id": "uOYqp0HWEqWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "slerp_model = merge(model1, model2, alpha=0.5)"
      ],
      "metadata": {
        "id": "KcmuYnr7EzWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def testy(model):\n",
        "  with torch.no_grad():\n",
        "    outputs = model(**input_ids)\n",
        "    preds = torch.argmax(outputs.logits, dim=-1)\n",
        "\n",
        "  correct = (preds == sample_labels).sum().item()\n",
        "  accuracy = correct / len(sample_labels)\n",
        "\n",
        "  acc = f\"SImple Accuracy TEST: {accuracy * 100:.2f}%\"\n",
        "  return acc"
      ],
      "metadata": {
        "id": "agViHhBsID_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TIES METHOD"
      ],
      "metadata": {
        "id": "r8cvmoOXO7-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ties_merge(param1, param2, trim_frac=0.2, alpha=None):\n",
        "    # Flatten\n",
        "    p1, p2 = param1.view(-1), param2.view(-1)\n",
        "\n",
        "    # ---- TRIM ----\n",
        "    k1 = int(len(p1) * trim_frac)\n",
        "    k2 = int(len(p2) * trim_frac)\n",
        "    thresh1 = p1.abs().kthvalue(len(p1)-k1).values\n",
        "    thresh2 = p2.abs().kthvalue(len(p2)-k2).values\n",
        "    p1_trim = torch.where(p1.abs() >= thresh1, p1, torch.zeros_like(p1))\n",
        "    p2_trim = torch.where(p2.abs() >= thresh2, p2, torch.zeros_like(p2))\n",
        "\n",
        "    # ---- ELECT SIGN ----\n",
        "    dominant = torch.where(p1_trim.abs() >= p2_trim.abs(), p1_trim, p2_trim)\n",
        "    sign_vector = dominant.sign()\n",
        "\n",
        "    # ---- DISJOINT MERGE ----\n",
        "    aligned_p1 = torch.where(p1_trim.sign() == sign_vector, p1_trim, torch.zeros_like(p1_trim))\n",
        "    aligned_p2 = torch.where(p2_trim.sign() == sign_vector, p2_trim, torch.zeros_like(p2_trim))\n",
        "\n",
        "    count = (aligned_p1.abs() > 0).int() + (aligned_p2.abs() > 0).int()\n",
        "    merged = (aligned_p1 + aligned_p2) / count.clamp(min=1)\n",
        "\n",
        "    return merged.view_as(param1)"
      ],
      "metadata": {
        "id": "PSkWY488Jn10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_loop(merge_fn, bert_model, distil_model, alpha=None):\n",
        "  new_state = distil_model.state_dict().copy()\n",
        "  #EMBEDDINGS\n",
        "  for key in ['embeddings.word_embeddings.weight', \"embeddings.position_embeddings.weight\"]:\n",
        "    new_state[key] = merge_fn(\n",
        "        bert_model.state_dict()[f\"bert.{key}\"],\n",
        "        distil_model.state_dict()[f\"distilbert.{key}\"],\n",
        "        alpha=alpha\n",
        "    )\n",
        "\n",
        "  #trransformer leayer\n",
        "  bert_layers = bert_model.bert.encoder.layer\n",
        "  distil_layers = distil_model.distilbert.transformer.layer\n",
        "\n",
        "  for distil_idx in range(6):\n",
        "    bert_idx1, bert_idx2 = 2*distil_idx, 2*distil_idx+1\n",
        "    bert_layer1 = bert_layers[bert_idx1].state_dict()\n",
        "    bert_layer2 = bert_layers[bert_idx2].state_dict()\n",
        "    distil_layer = distil_layers[distil_idx].state_dict()\n",
        "\n",
        "    merged={}\n",
        "    for k in distil_layer.keys():\n",
        "      if 'q_lin' in k:\n",
        "        k_bert = \"attention.self.query.\" + k.split(\".\")[-1]\n",
        "\n",
        "      elif \"k_lin\" in k:\n",
        "        k_bert = \"attention.self.key.\" + k.split(\".\")[-1]\n",
        "      elif 'v_lin' in k:\n",
        "        k_bert = \"attention.self.value.\" + k.split(\".\")[-1]\n",
        "      elif 'out_lin' in k:\n",
        "        k_bert = \"attention.output.dense.\" + k.split(\".\")[-1]\n",
        "      elif \"ffn.lin1\" in k:\n",
        "        k_bert = \"intermediate.dense.\" + k.split(\".\")[-1]\n",
        "\n",
        "      elif 'ffn.lin2' in k:\n",
        "        k_bert = \"output.dense.\" + k.split(\".\")[-1]\n",
        "\n",
        "      elif \"sa_layer_norm\" in k:\n",
        "        k_bert = \"attention.output.LayerNorm.\" + k.split(\".\")[-1]\n",
        "      elif \"output_layer_norm\" in k:\n",
        "        k_bert = \"output.LayerNorm.\" + k.split(\".\")[-1]\n",
        "      else:\n",
        "        continue\n",
        "\n",
        "      bert_avg = 0.5 * bert_layer1[k_bert] + 0.5 * bert_layer2[k_bert]\n",
        "      merged[k] = merge_fn(bert_avg, distil_layer[k], alpha=alpha)\n",
        "\n",
        "    for k,v in merged.items():\n",
        "      new_state[f\"distilbert.transformer.layer.{distil_idx}.{k}\"] = v\n",
        "\n",
        "  if 'pre_classifier.weight' in new_state:\n",
        "    new_state['pre_classifier.weight'] = distil_model.state_dict()[\"pre_classifier.weight\"]\n",
        "    new_state[\"pre_classifier.bias\"]   = distil_model.state_dict()[\"pre_classifier.bias\"]\n",
        "\n",
        "  distil_model.load_state_dict(new_state, strict=False) #strict prevents crashing when some leys dont match\n",
        "  return distil_model"
      ],
      "metadata": {
        "id": "Ni911u_dElDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ties_model = merge_loop(ties_merge, model1, model2)"
      ],
      "metadata": {
        "id": "PwSpggotQXpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bb = testy(ties_model)\n",
        "bb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zxevBloHQrJn",
        "outputId": "7725cb66-e234-4f00-c24d-2c7151156d38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'SImple Accuracy TEST: 40.00%'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#DARE METHOD"
      ],
      "metadata": {
        "id": "NN9SpQ9tQugQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from copy import deepcopy"
      ],
      "metadata": {
        "id": "FFBY2uJRRxFO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dare_merge(bert_model, distil_model, drop_prob=0.2):\n",
        "  new_state = distil_model.state_dict().copy()\n",
        "  for key in ['embeddings.word_embeddings.weight', \"embeddings.position_embeddings.weight\"]:\n",
        "    new_state[key] = 0.5 * (bert_model.state_dict()[f\"bert.{key}\"] + \\\n",
        "                            distil_model.state_dict()[f\"distilbert.{key}\"]\n",
        "    )\n",
        "  bert_layers = bert_model.bert.encoder.layer\n",
        "  distil_layers = distil_model.distilbert.transformer.layer\n",
        "  keep_prob = 1 - drop_prob\n",
        "  scale = 1.0/ keep_prob\n",
        "\n",
        "  for distil_idx in range(6):\n",
        "\n",
        "    bert_idx1, bert_idx2 = 2*distil_idx, 2*distil_idx+1\n",
        "    bert_layer1 = bert_layers[bert_idx1].state_dict()\n",
        "    bert_layer2 = bert_layers[bert_idx2].state_dict()\n",
        "    distil_layer = distil_layers[distil_idx].state_dict()\n",
        "\n",
        "    merged={}\n",
        "\n",
        "    for k in distil_layer.keys():\n",
        "      if 'q_lin' in k:\n",
        "        k_bert = \"attention.self.query.\" + k.split(\".\")[-1]\n",
        "      elif \"k_lin\" in k:\n",
        "        k_bert = \"attention.self.key.\" + k.split(\".\")[-1]\n",
        "      elif 'v_lin' in k:\n",
        "        k_bert = \"attention.self.value.\" + k.split(\".\")[-1]\n",
        "      elif 'out_lin' in k:\n",
        "        k_bert = \"attention.output.dense.\" + k.split(\".\")[-1]\n",
        "      elif \"ffn.lin1\" in k:\n",
        "        k_bert = \"intermediate.dense.\" + k.split(\".\")[-1]\n",
        "\n",
        "      elif 'ffn.lin2' in k:\n",
        "        k_bert = \"output.dense.\" + k.split(\".\")[-1]\n",
        "      elif \"sa_layer_norm\" in k:\n",
        "        k_bert = \"attention.output.LayerNorm.\" + k.split(\".\")[-1]\n",
        "      elif \"output_layer_norm\" in k:\n",
        "        k_bert = \"output.LayerNorm.\" + k.split(\".\")[-1]\n",
        "      else:\n",
        "        continue\n",
        "      bert_avg = 0.5 * bert_layer1[k_bert] + 0.5 * bert_layer2[k_bert]\n",
        "      mask = (torch.rand_like(bert_avg) < keep_prob).float()\n",
        "      bert_avg = bert_avg * mask * scale\n",
        "\n",
        "      merged_param = (bert_avg + distil_layer[k])/ 2.0\n",
        "      merged[k] = merged_param\n",
        "\n",
        "    for k,v in merged.items():\n",
        "      new_state[f\"distilbert.transformer.layer.{distil_idx}.{k}\"] = v\n",
        "\n",
        "  if 'pre_classifier.weight' in new_state:\n",
        "    new_state['pre_classifier.weight'] = distil_model.state_dict()[\"pre_classifier.weight\"]\n",
        "    new_state[\"pre_classifier.bias\"]   = distil_model.state_dict()[\"pre_classifier.bias\"]\n",
        "  distil_model.load_state_dict(new_state, strict=False)\n",
        "  return distil_model\n",
        "\n"
      ],
      "metadata": {
        "id": "12ziBjqFQ19M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dare_model = dare_merge(model1, model2)"
      ],
      "metadata": {
        "id": "zVRudWspQ15n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cc = testy(dare_model)\n",
        "cc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jpEehwygQubv",
        "outputId": "50e8c1f4-41a8-44f0-83e6-59ee359ccc54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'SImple Accuracy TEST: 40.00%'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rblc1ks4WoyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "o_rJIlQXWouE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "me7hxsljWopO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MIaqV6YlVH2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iyHdoxNJVHyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Qx8MTNviUXcu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eFx-dQ3UUXYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VX2H5g8QUXUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NAqTxWXdQaI5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}